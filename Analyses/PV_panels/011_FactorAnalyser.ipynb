{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-a067076e50ef>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-a067076e50ef>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    with tf.name_scope(''):\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Assume that we are receiving a batch of 40x40 pixel patches\n",
    "# The associated set of labels indicates whether or not a patch contains a crack\n",
    "# These labels are one-hot encoded.\n",
    "\n",
    "patch_size  = 40\n",
    "input_size  = patch_size**2\n",
    "batch_size  = 32\n",
    "in_channels = 1\n",
    "n_factors   = 2\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('Inputs'):\n",
    "        images = tf.placeholder(tf.float32, [batch_size, input_size, in_channels])\n",
    "        labels = tf.placeholder(tf.float32, [batch_size, 2])\n",
    "    \n",
    "    with tf.name_scope('Variables'):\n",
    "        mu    = tf.Variable(tf.truncated_normal(\n",
    "                                shape = [input_size]))\n",
    "        Sigma = tf.Variable(tf.eye(input_size))\n",
    "        Phi   = tf.Variable(tf.truncated_normal(\n",
    "                                shape = [input_size, n_factors]))\n",
    "        \n",
    "    def E_step(X, Phi, Sigma, mu):\n",
    "        \"\"\"\n",
    "            Returns a [batch_size, n_factors] matrix.\n",
    "        \n",
    "            X     : [batch_size, input_size] matrix of observations.\n",
    "            Phi   : [input_size, n_factors] matrix of factors.\n",
    "            Sigma : [input_size, input_size] diagonal covariance matrix.\n",
    "            mu    : [input_size] vector located at x's mean.\n",
    "        \"\"\"\n",
    "        inv_Sigma = tf.diag(tf.divide(1, tf.diag_part(Sigma)))\n",
    "        tmp1      = tf.tensordot(tf.tranpose(Phi), inv_Sigma, axes = [[0], [1]])\n",
    "        tmp2      = tf.tensordot(tmp1, Phi, axes = [[0], [1]]) # [n_factors, n_factors]\n",
    "        tmp3      = tf.tensordot(tf.inverse(tmp2 + tf.eye(n_factors)), tmp1, axes = [[0], [1]])\n",
    "        Eh        = tf.tensordot(X - mu, tf.transpose(tmp3), axes = [[0], [1]])\n",
    "        Ehh       = tmp3 + tf.tensordot(Eh, tf.tranpose(Eh), axes = [[0], [1]])\n",
    "        return Eh, Ehh\n",
    "    \n",
    "    def M_step(X, mu, Phi, Eh, Ehh, batch_size):\n",
    "        mu      = update_mu(mu, batch_size)\n",
    "        Phi     = update_Phi(X, mu, Eh, Ehh)\n",
    "        Sigma   = update_Sigma(X, mu, Phi, Eh, batch_size)\n",
    "        return mu, Phi, Sigma\n",
    "    \n",
    "    def update_mu(mu, batch_size):\n",
    "        mu_hat = tf.sum(X, axis = 0)/batch_size\n",
    "        return mu_hat\n",
    "    \n",
    "    def update_Phi(X, mu, Eh, Ehh):\n",
    "        X        = tf.expand_dims(X, axis = 0)  # X is flat and wide, depth corresponds to inidivdual samples\n",
    "        Eh       = tf.expand_dims(Eh, axis = 0) # It's the same case with Eh\n",
    "        tmp1     = tf.tensordot(X - mu, tf.transpose(Eh, perm = [2, 0, 1]), axis = [[]])\n",
    "        Phi_hat  = tf.tensordot(tmp1, tmp2, axis = [[0], [1]])\n",
    "        return Phi_hat\n",
    "    \n",
    "    def update_Sigma(X, mu, Phi, Eh, batch_size):\n",
    "        tmp1     = tf.tensordot(X)\n",
    "        \n",
    "    with tf.name_scope('Optimization'):\n",
    "        Eh, Ehh        = E_step(X, Phi, Sigma, mu) # [batch_size, n_factors] - Each row corresponds to a single example\n",
    "        mu, Phi, Sigma = M_step(X, mu, Phi, Eh, Ehh, batch_size)\n",
    "        optimize       = tf.group(mu, Phi, Sigma)\n",
    "        \n",
    "    with tf.name_scope('Inference'):"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
