{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Import data.\n",
    "# 2. Set up a small graph.\n",
    "# 3. Train the model against it.\n",
    "# 4. Save the model.\n",
    "# 5. Restore and continue to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Import data (it has already been scaled and centered).\n",
    "image_size  = 10\n",
    "n_channels  = 1\n",
    "\n",
    "def reformat(data): # Adds the channel dimension to the numpy arrays\n",
    "    data = data.reshape( (-1, image_size, image_size, n_channels))  # -1 implies the dimension is inferred\n",
    "    return data\n",
    "\n",
    "def load_pickled_data(name):\n",
    "    data   = pickle.load(open(name+'_dataset.p', 'rb'))\n",
    "    labels = pickle.load(open(name+'_labels.p', 'rb'))\n",
    "    return reformat(data), labels\n",
    "\n",
    "data = {}; labels = {};\n",
    "\n",
    "data['train'], labels['train'] = load_pickled_data('../data/train')\n",
    "data['valid'], labels['valid'] = load_pickled_data('../data/valid')\n",
    "data['test'], labels['test']   = load_pickled_data('../data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. Configure a simple 2-layer graph.\n",
    "\n",
    "batch_size  = 16\n",
    "n_classes   = 2\n",
    "output_channels = [64, 128, 1024]\n",
    "filter_size     = [3, 3]\n",
    "\n",
    "# 10 x 10 input\n",
    "# Convolve with 64 3 x 3 filters, stride 1 (out. image size of 10 x 10)\n",
    "# Convolve with 128 3 x 3 filters, stride 2 (out. image size of 5 x 5)\n",
    "# Fully connected layer (1024 nodes)\n",
    "# Softmax output\n",
    "\n",
    "simple_graph = tf.Graph()\n",
    "\n",
    "with simple_graph.as_default():\n",
    "    # Placeholders and constants\n",
    "    tf_train_data   = tf.placeholder(tf.float32, [batch_size, image_size, image_size, n_channels]) # BWHN\n",
    "    tf_train_labels = tf.placeholder(tf.float32, [batch_size, n_classes])\n",
    "    tf_valid_data   = tf.constant(data['valid'])\n",
    "    tf_test_data    = tf.constant(data['test'])\n",
    "    \n",
    "    # Variables\n",
    "    filters1 = tf.Variable(tf.truncated_normal(\n",
    "                    [filter_size[0], filter_size[0], n_channels, output_channels[0]], stddev = 0.01))\n",
    "    biases1  = tf.Variable(tf.zeros([output_channels[0]]))\n",
    "    \n",
    "    filters2 = tf.Variable(tf.truncated_normal(\n",
    "                    [filter_size[1], filter_size[1], output_channels[0], output_channels[1]], stddev = 0.01))\n",
    "    biases2  = tf.Variable(tf.zeros([output_channels[1]]))\n",
    "    \n",
    "    weights3 = tf.Variable(tf.truncated_normal(\n",
    "                    [output_channels[1] * image_size // 2 * image_size // 2, n_classes], stddev = 0.01))\n",
    "    biases3  = tf.Variable(tf.zeros(n_classes))\n",
    "    \n",
    "    def model(data):\n",
    "        # Layer 1 : 20 x 20 x 1 input ; 10 x 10 x 64 output ; (3 x 3 x 1) x 64 filters ; stride of 2 ; same padding\n",
    "        conv = tf.nn.conv2d(data, filters1, strides = [1, 1, 1, 1], padding = 'SAME', use_cudnn_on_gpu = True)\n",
    "        act  = tf.nn.relu(conv + biases1)\n",
    "        \n",
    "        # Layer 2 : 10 x 10 x 64 input ; 5 x 5 x 128 output ; (3 x 3 x 64) x 128 filters ; stride of 2 ; same padding\n",
    "        conv = tf.nn.conv2d(act, filters2, strides = [1, 2, 2, 1], padding = 'SAME', use_cudnn_on_gpu = True)\n",
    "        act  = tf.nn.relu(conv + biases2)\n",
    "        \n",
    "        # layer 3 : fully connected ; 5*5*128 input ; (5*5*128 x 2) filters\n",
    "        shape  = act.get_shape().as_list()\n",
    "        act    = tf.reshape(act, [shape[0], shape[1]*shape[2]*shape[3]])\n",
    "        logits = tf.nn.relu(tf.matmul(act, weights3) + biases3)\n",
    "        return logits\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    logits = model(tf_train_data)\n",
    "    loss   = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = tf_train_labels))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n",
    "    \n",
    "    # Feedback information\n",
    "    tf_train_predictions = tf.nn.softmax(logits)\n",
    "    tf_valid_predictions = tf.nn.softmax(model(tf_valid_data))\n",
    "    tf_test_predictions  = tf.nn.softmax(model(tf_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "------------\n",
      "Minibatch loss: 000.69\n",
      "\n",
      "Minibatch accuracy: 56.25%\n",
      "\n",
      "Validation accuracy: 41.02%\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-90f19e1be4f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtf_train_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_predictions\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_train_predictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. Create and run a session.\n",
    "\n",
    "def accuracy_score(pred, true):\n",
    "    return 100*np.sum(np.equal(np.argmax(pred, axis = 1), np.argmax(true, axis = 1)))/pred.shape[0]\n",
    "\n",
    "def minibatch(data, labels, batch_size, step):\n",
    "    posn         = (step * batch_size) % (data.shape[0] - batch_size)\n",
    "    batch_data   = data[posn:(posn + batch_size), :, :, :]\n",
    "    batch_labels = labels[posn:(posn + batch_size), :]\n",
    "    return batch_data, batch_labels\n",
    "\n",
    "def performance_report(step, loss, train_predictions, train_labels):\n",
    "    print('Step {}\\n------------'.format(step))\n",
    "    print('Minibatch loss: {:06.2f}\\n'.format(loss))\n",
    "    print('Minibatch accuracy: {:04.2f}%\\n'.format(accuracy_score(train_predictions, train_labels)))\n",
    "    print('Validation accuracy: {:04.2f}%\\n\\n'.format(accuracy_score(tf_valid_predictions.eval(), labels['valid'])))\n",
    "\n",
    "\n",
    "n_steps = 10001\n",
    "\n",
    "with tf.Session(graph = simple_graph) as session:\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        batch_data, batch_labels = minibatch(data['train'], labels['train'], batch_size, step)\n",
    "        fd = {tf_train_data:batch_data, tf_train_labels:batch_labels}\n",
    "        \n",
    "        _, l, batch_predictions  = session.run([optimizer, loss, tf_train_predictions], feed_dict = fd)\n",
    "        \n",
    "        if step % 2000 == 0:\n",
    "            performance_report(step, l, batch_predictions, batch_labels)\n",
    "            \n",
    "    print('Testing accuracy @ {} steps: {:04.2f}%'.format(n_steps,\n",
    "                                                          accuracy_score(tf_test_predictions.eval(), labels['test'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
