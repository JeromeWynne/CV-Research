{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a label indicating which of $M$ possible identities a face belongs to, based on a vector of grayscale pixel intensities $x$. Model the likelihood for each class using a factor analyzer:\n",
    "\n",
    "$$\n",
    "    \\text{Pr}(x \\ | \\ w_i = k) = \\text{Norm}_{x}(\\mu_k, \\phi_k\\phi_k^T + \\Sigma_k)\\\\[0.7em]\n",
    "$$\n",
    "Learn the parameters for the $k$th identity using the images of faces corresponding to that identity. Use expecation maximization to learn these parameters. Assign priors $\\text{Pr}(w = k)$ according to each face's prevalence in the database. To evaluate a new face image $x_i$, compute the posterior $\\text{Pr}(w_i|x_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data:            Continuous - vectors of grayscale pixel intensities.\n",
    "# World states:    Discrete - categories corresponding to face identities.\n",
    "# Model:           Generative - factor analyzers each parameterized by unique means, factors, and diagonal covariance matrices.\n",
    "# Learning:        Expectation maximization of each model's parameters against images of their corresponding face IDs.\n",
    "# Inference:       Computation of the posterior over face IDs, given an input face image vector.\n",
    "\n",
    "# Requirements:\n",
    "#   Data      -> [dt] Dataset of (preferably grayscale) face images and their corresponding IDs\n",
    "#   General   -> [fn] Multivariate normal density function\n",
    "#   Learner   -> [fn] EM algorithm to fit class means, factors, and covariance matrices\n",
    "#   Inference -> [fn] Inference     - Receives image vector, returns class probabilities\n",
    "#             -> [st] Class priors  - Class priors indexed by world state\n",
    "#             -> [fn] Class prior learner - Receives training set, returns vector of class priors\n",
    "#             -> [fn] Likelihood   - Receives image vector + world state, returns probability\n",
    "#             -> [fn] Likelihood learner - Receives training set, returns array of lists (likelihood parameters by class)\n",
    "\n",
    "\n",
    "# 1. Import and flatten the data.\n",
    "# 2. Fit the prior distribution     : prior = fit_prior(vector of class labels)\n",
    "#    1.1. Compute and return the relative class sizes.\n",
    "# 3. Fit the likelihood distribution: likelihood_parameters = fit_likelihood(matrix of image vectors, vector of class labels, n_factors)\n",
    "#   3.1. Iterate over each class and maximize its images' likelihoods - Pr(x|w,th) - wr.t. th via EM.\n",
    "#        -> Call: [mu_k, phi_k, covar_k] = EM(matrix of class image vectors, n_factors)\n",
    "#       3.1.1. Randomly initialize vector mu_k, matrix phi_k, diag. matrix covar_k.\n",
    "#       3.1.2. E-step: Maximize the boundary w.r.t. the density functions over the hidden variable.\n",
    "#       3.1.3. M-step: Maximize the boundary's value w.r.t. mu_k, phi_k, and covar_k.\n",
    "#       3.1.4. B-step: Compute the boundary's value given the parameters and density functions.\n",
    "#    3.2. Store [mu_k, phi_k, covar_k] in an array such that they are indexed by world state.\n",
    "#    3.3. Return the array of parameter values.\n",
    "#  4. Inference: [vector of class probabilities] = posterior(input_vec, parameter_arr)\n",
    "#    4.1. Compute the product likelihood(input_vec, parameter_arr, k)*prior[k] for all world states k.\n",
    "#       4.1.1. likelihood() is a multivariate normal density calculation.\n",
    "#    4.2. Normalize and return this vector of unnormalized probabilities.\n",
    "# 5. Display the image along with the computed class probabilities.\n",
    "\n",
    "# What do the factors represent? Directions in which covariance is greatest among pixels.\n",
    "# *Extracting the factors and plotting them as images would be interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
