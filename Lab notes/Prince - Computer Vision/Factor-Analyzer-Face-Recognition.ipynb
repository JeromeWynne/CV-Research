{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a label indicating which of $M$ possible identities a face belongs to, based on a vector of grayscale pixel intensities $x$. Model the likelihood for each class using a factor analyzer:\n",
    "\n",
    "$$\n",
    "    \\text{Pr}(x \\ | \\ w_i = k) = \\text{Norm}_{x}(\\mu_k, \\phi_k\\phi_k^T + \\Sigma_k)\\\\[0.7em]\n",
    "$$\n",
    "Learn the parameters for the $k$th identity using the images of faces corresponding to that identity. Use expecation maximization to learn these parameters. Assign priors $\\text{Pr}(w = k)$ according to each face's prevalence in the database. To evaluate a new face image $x_i$, compute the posterior $\\text{Pr}(w_i|x_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data:            Continuous - vectors of grayscale pixel intensities.\n",
    "# World states:    Discrete - categories corresponding to face identities.\n",
    "# Model:           Generative - factor analyzers each parameterized by unique means, factors, and diagonal covariance matrices.\n",
    "# Learning:        Expectation maximization of each model's parameters against images of their corresponding face IDs.\n",
    "# Inference:       Computation of the posterior over face IDs, given an input face image vector.\n",
    "\n",
    "# Requirements:\n",
    "#             -> [st] training_data[]    - Array with rows of grayscale face images \n",
    "#             -> [st] training_labels[]  - Vector of the faces' corresponding IDs\n",
    "#             -> [fn] dnorm()            - Multivariate normal density function\n",
    "#             -> [fn] posterior()        - Receives image vector, returns class probabilities\n",
    "#             -> [st] priors[]           - Class priors indexed by world state\n",
    "#             -> [fn] fit_priors()       - Receives training set, returns vector of class priors\n",
    "#             -> [fn] likelihood()       - Receives image vector + world state, returns probability\n",
    "#             -> [fn] fit_likelihoods()  - Iterates over world states and fits their corresponding likelihood functions\n",
    "#             -> [fn] EM()               - Maximizes likelihood for fit_likelihoods()\n",
    "#             -> [fn] E_step()           - Computes hidden variable posteriors for EM()\n",
    "#             -> [fn] M_step()           - Maximizes boundary w.r.t. likelihood fn parameters for EM()\n",
    "#             -> [fn] boundary()         - Computes boundary value for EM()\n",
    "#             -> [st] likelihood_params[]- List containing parameters corresponding to kth likelihood function\n",
    "#             -> [st] test_data[]        - Vector of test image grayscale pixel intensities\n",
    "\n",
    "#` 1. Import and flatten the data.\n",
    "#` 2. Fit the prior distribution     : prior = fit_prior(vector of class labels)\n",
    "#`    1.1. Compute and return the relative class sizes.\n",
    "#` 3. Fit the likelihood distribution: likelihood_parameters = fit_likelihood(matrix of image vectors, vector of class labels, n_factors)\n",
    "#`   3.1. Iterate over each class and maximize its images' likelihoods - Pr(x|w,th) - wr.t. th via EM.\n",
    "#        -> Call: [mu_k, phi_k, covar_k] = EM(matrix of class image vectors, n_factors)\n",
    "#       3.1.1. Randomly initialize vector mu_k, matrix phi_k, diag. matrix covar_k.\n",
    "#       3.1.2. E_step(): Maximize the boundary w.r.t. the density functions over the hidden variable.\n",
    "#       3.1.3. M_step(): Maximize the boundary's value w.r.t. mu_k, phi_k, and covar_k.\n",
    "#       3.1.4. boundary(): Compute the boundary's value given the parameters and density functions.\n",
    "#`    3.2. Store [mu_k, phi_k, covar_k] in an array such that they are indexed by world state.\n",
    "#`    3.3. Return the array of parameter values.\n",
    "#  4. Inference: [vector of class probabilities] = posterior(input_vec, parameter_arr)\n",
    "#    4.1. Compute the product likelihood(input_vec, parameter_arr, k)*prior[k] for all world states k.\n",
    "#       4.1.1. likelihood() is a multivariate normal density calculation.\n",
    "#    4.2. Normalize and return this vector of unnormalized probabilities.\n",
    "# 5. Display the image along with the computed class probabilities.\n",
    "\n",
    "# What do the factors represent? Directions in which covariance is greatest among pixels.\n",
    "# *Extracting the factors and plotting them as images would be interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pytest\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import and label the training data\n",
    "face_ids        = [fp[-6:] for fp in glob.iglob('.\\\\data\\\\face-identification\\\\select-faces\\\\*')]\n",
    "face_fps        = glob.glob('.\\\\data\\\\face-identification\\\\select-faces\\\\*\\\\*.jpg')\n",
    "training_data   = np.array([np.ravel(imresize(imread(fp, flatten=True)/255, size = [50, 50])) for fp in face_fps])\n",
    "training_labels = [face_ids.index(name) for name in [fp.split('\\\\')[-2] for fp in face_fps]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test functions for fit_likelihood()\n",
    "def test_likelihood_inputs(training_data, training_labels, n_factors):\n",
    "    assert n_factors > 0\n",
    "    assert type(training_labels)    == list\n",
    "    assert type(training_data)      == np.ndarray\n",
    "    assert type(training_labels[0]) == int\n",
    "    assert len(training_labels)     == training_data.shape[0]\n",
    "\n",
    "def test_likelihood_outputs(klikelihood_params, datum_length, n_factors):\n",
    "    assert test_likelihood_mean_dim(klikelihood_params[1], datum_length)\n",
    "    assert test_likelihood_factor_dim(klikelihood_params[2], datum_length, n_factors)\n",
    "    assert test_likelihood_covar_dim(klikelihood_params[3], datum_length)\n",
    "    assert test_likelihood_covar_psd(klikelihood_params[3])\n",
    "    assert test_likelihood_covar_sym(klikelihood_params[3])\n",
    "\n",
    "def test_likelihood_mean_dim(mean_vector, datum_length):\n",
    "    assert len(mean_vector) == datum_length\n",
    "\n",
    "def test_likelihood_factor_dim(factor_matrix, datum_length, n_factors):\n",
    "    assert factor_matrix.shape == (datum_length, n_factors)\n",
    "\n",
    "def test_likelihood_covar_positive(covar_matrix):\n",
    "    assert np.all(covar_matrix >= 0)\n",
    "    \n",
    "def test_likelihood_covar_dim(covar_matrix, datum_length):\n",
    "    assert covar_matrix.shape == (datum_length, datum_length)\n",
    "    \n",
    "def test_likelihood_covar_sym(covar_matrix):\n",
    "    assert np.all(covar_matrix == covar_matrix.T)\n",
    "\n",
    "def test_likelihood_covar_psd(covar_matrix):\n",
    "    assert np.all(np.linalg.eigvals(covar_matrix) >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_prior(training_labels):\n",
    "    # Receives a list of training labels indicating face ID\n",
    "    # Returns a numpy array of ID prior probabilities\n",
    "    priors = [sum(training_labels == ID)/len(training_labels) for ID in np.unique(training_labels)]\n",
    "    return np.array(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_likelihood(training_data, training_labels, n_factors):\n",
    "    # training_data   -> numpy array with rows of grayscale image vectors\n",
    "    # training_labels -> list of associated integer face IDs\n",
    "    # n_factors       -> Number of factors to use in factor analyzer\n",
    "    # Iterates over world states and fits the parameters of their associated likelihood distributions\n",
    "    test_likelihood_inputs(training_data, training_labels, n_factors)\n",
    "    class_IDs         = np.unique(training_labels)\n",
    "    likelihood_params = [None]*len(class_IDs) # List containing a set of parameters for each world state\n",
    "    datum_length      = training_data.shape[1]\n",
    "    for k in np.unique(class_IDs):\n",
    "        k_data               = training_data[training_labels == k, :] # Images containing kth person\n",
    "        klikelihood_params   = EM(k_data, n_factors, datum_length) # Fit the kth FA's parameters -> [mu_k, phi_k, covar_k]\n",
    "        #assert test_likelihood_outputs(klikelihood_params, datum_length, n_factors)\n",
    "        likelihood_params[k] = klikelihood_params\n",
    "    return likelihood_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def EM(training_data, n_factors, datum_length):\n",
    "    # Returns parameters that fit a factor analyzer to the given data\n",
    "    # training_data -> np array with rows of vectorized input images\n",
    "    # n_factors     -> Number of factors to model the data's covariance with\n",
    "    # 1. Randomly initialize parameters\n",
    "    training_data = np.mat(training_data)\n",
    "    mu_upd      = np.mat(np.random.uniform([1]*datum_length)).T # Vector\n",
    "    phi_upd     = np.mat([np.random.normal(size = n_factors) for _ in range(datum_length)]) # Matrix\n",
    "    covar_upd   = np.mat(np.random.normal(0, 100)*np.identity(datum_length))\n",
    "    n_datum = training_data.shape[0]\n",
    "    # 2. Iterate over E and M steps until boundary ceases to shift\n",
    "    error = 1e5\n",
    "    while (error > 1) :\n",
    "        [mu, phi, covar]             = [mu_upd, phi_upd, covar_upd]\n",
    "        expectations                 = E_step(training_data, mu, phi, covar, n_datum) # [N x 2] np.array: [(E[h_i], E[h_i h_i.T]), ...]\n",
    "        [mu_upd, phi_upd, covar_upd] = M_step(training_data, expectations, n_datum) #\n",
    "        mu_error                    = np.max(abs(mu_upd - mu))\n",
    "        phi_error                   = np.max(abs(phi_upd - phi))\n",
    "        covar_error                 = np.max(abs(covar_upd - covar))\n",
    "        error = max([phi_error, mu_error, covar_error])\n",
    "        print(error)\n",
    "    return [mu_upd, phi_upd, covar_upd]\n",
    "# The hidden variable is a vector describing the shift in the normal's mean through the subspace - this shift is conditional\n",
    "# on each image, meaning that well-represented images will produce many shifts to a particular part of the subspace. This\n",
    "# further means that the factors will tend to be aligned in the direction of shift (see the computation of the factors in\n",
    "# the M-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def E_step(training_data, mu, phi, covar, n_datum):\n",
    "    I  = np.identity(phi.shape[1])\n",
    "    expectations = [None]*n_datum\n",
    "    for i in range(n_datum):\n",
    "        x                = np.mat(training_data[i, :]).T\n",
    "        inv_term         = np.linalg.inv(phi.T * np.diag(1/np.diag(covar)) * phi + I)\n",
    "        E_h              = inv_term * phi.T  * np.diag(1/np.diag(covar)) * (x - mu)\n",
    "        E_hh             = inv_term + E_h * E_h.T\n",
    "        expectations[i]  = [E_h, E_hh]\n",
    "    return expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def M_step(training_data, expectations, n_datum):\n",
    "    x         = training_data\n",
    "    # Mu\n",
    "    mu_hat    = np.sum(training_data, axis = 0).T/n_datum\n",
    "    # Phi\n",
    "    list_E_h  = np.array([expec[0] for expec in expectations])\n",
    "    list_E_hh = np.array([expec[1] for expec in expectations])\n",
    "    phi_t1    = np.sum(np.array([(x[i, :].T - mu_hat) * list_E_h[i].T for i in range(n_datum)]), axis = 0)\n",
    "    phi_t2    = np.linalg.inv(np.sum(list_E_hh, axis = 0))\n",
    "    phi_hat   = np.mat(phi_t1) * np.mat(phi_t2)\n",
    "    # Sigma\n",
    "    sum_of_sq = 0\n",
    "    for i in range(n_datum):\n",
    "        sum_of_sq += np.diag(((x[i, :].T - mu_hat) * (x[i, :].T - mu_hat).T)\n",
    "                             - (phi_hat * list_E_h[i] * (x[i, :].T - mu_hat).T))/n_datum\n",
    "    covar_hat  = np.identity(len(mu_hat))\n",
    "    np.fill_diagonal(covar_hat, sum_of_sq)\n",
    "    return [mu_hat, phi_hat, covar_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011.36503356\n",
      "1262.14918684\n",
      "266.103541779\n",
      "302.121345996\n",
      "198.447806517\n",
      "80.6063929915\n",
      "30.0745586739\n",
      "11.1272194707\n",
      "4.12703770217\n",
      "1.53412638016\n",
      "0.57100258684\n",
      "1807.61138843\n",
      "1579.40775119\n",
      "193.746803329\n",
      "81.2031930013\n",
      "44.005100597\n",
      "26.222568785\n",
      "16.3913614937\n",
      "10.71217962\n",
      "7.27184057377\n",
      "5.13328835744\n",
      "3.63523825043\n",
      "2.58231370543\n",
      "1.83926263358\n",
      "1.31272831158\n",
      "0.938332758914\n",
      "1934.00135775\n",
      "1840.76784818\n",
      "60.3855655467\n",
      "33.775147353\n",
      "23.6271493027\n",
      "16.5643714235\n",
      "11.2882225335\n",
      "7.57331585247\n",
      "5.03429733331\n",
      "3.32730036561\n",
      "2.19085889397\n",
      "1.43892940912\n",
      "0.943432249378\n"
     ]
    }
   ],
   "source": [
    "n_factors = 1\n",
    "fit_parameters = fit_likelihood(training_data, training_labels, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 49.5, 49.5, -0.5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x83807b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(fit_parameters[0][0], [50, 50]), cmap = 'gray');\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
