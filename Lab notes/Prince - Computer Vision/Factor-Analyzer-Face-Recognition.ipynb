{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a label indicating which of $M$ possible identities a face belongs to, based on a vector of grayscale pixel intensities $x$. Model the likelihood for each class using a factor analyzer:\n",
    "\n",
    "$$\n",
    "    \\text{Pr}(x \\ | \\ w_i = k) = \\text{Norm}_{x}(\\mu_k, \\phi_k\\phi_k^T + \\Sigma_k)\\\\[0.7em]\n",
    "$$\n",
    "Learn the parameters for the $k$th identity using the images of faces corresponding to that identity. Use expecation maximization to learn these parameters. Assign priors $\\text{Pr}(w = k)$ according to each face's prevalence in the database. To evaluate a new face image $x_i$, compute the posterior $\\text{Pr}(w_i|x_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data:            Continuous - vectors of grayscale pixel intensities.\n",
    "# World states:    Discrete - categories corresponding to face identities.\n",
    "# Model:           Generative - factor analyzers each parameterized by unique means, factors, and diagonal covariance matrices.\n",
    "# Learning:        Expectation maximization of each model's parameters against images of their corresponding face IDs.\n",
    "# Inference:       Computation of the posterior over face IDs, given an input face image vector.\n",
    "\n",
    "# Requirements:\n",
    "#             -> [st] training_data[]    - Array with rows of grayscale face images \n",
    "#             -> [st] training_labels[]  - Vector of the faces' corresponding IDs\n",
    "#             -> [fn] dnorm()            - Multivariate normal density function\n",
    "#             -> [fn] posterior()        - Receives image vector, returns class probabilities\n",
    "#             -> [st] priors[]           - Class priors indexed by world state\n",
    "#             -> [fn] fit_priors()       - Receives training set, returns vector of class priors\n",
    "#             -> [fn] likelihood()       - Receives image vector + world state, returns probability\n",
    "#             -> [fn] fit_likelihoods()  - Iterates over world states and fits their corresponding likelihood functions\n",
    "#             -> [fn] EM()               - Maximizes likelihood for fit_likelihoods()\n",
    "#             -> [fn] E_step()           - Computes hidden variable posteriors for EM()\n",
    "#             -> [fn] M_step()           - Maximizes boundary w.r.t. likelihood fn parameters for EM()\n",
    "#             -> [fn] boundary()         - Computes boundary value for EM()\n",
    "#             -> [st] likelihood_params[]- List containing parameters corresponding to kth likelihood function\n",
    "#             -> [st] test_data[]        - Vector of test image grayscale pixel intensities\n",
    "\n",
    "#` 1. Import and flatten the data.\n",
    "#` 2. Fit the prior distribution     : prior = fit_prior(vector of class labels)\n",
    "#`    1.1. Compute and return the relative class sizes.\n",
    "#` 3. Fit the likelihood distribution: likelihood_parameters = fit_likelihood(matrix of image vectors, vector of class labels, n_factors)\n",
    "#`   3.1. Iterate over each class and maximize its images' likelihoods - Pr(x|w,th) - wr.t. th via EM.\n",
    "#        -> Call: [mu_k, phi_k, covar_k] = EM(matrix of class image vectors, n_factors)\n",
    "#       3.1.1. Randomly initialize vector mu_k, matrix phi_k, diag. matrix covar_k.\n",
    "#       3.1.2. E_step(): Maximize the boundary w.r.t. the density functions over the hidden variable.\n",
    "#       3.1.3. M_step(): Maximize the boundary's value w.r.t. mu_k, phi_k, and covar_k.\n",
    "#       3.1.4. boundary(): Compute the boundary's value given the parameters and density functions.\n",
    "#`    3.2. Store [mu_k, phi_k, covar_k] in an array such that they are indexed by world state.\n",
    "#`    3.3. Return the array of parameter values.\n",
    "#  4. Inference: [vector of class probabilities] = posterior(input_vec, parameter_arr)\n",
    "#    4.1. Compute the product likelihood(input_vec, parameter_arr, k)*prior[k] for all world states k.\n",
    "#       4.1.1. likelihood() is a multivariate normal density calculation.\n",
    "#    4.2. Normalize and return this vector of unnormalized probabilities.\n",
    "# 5. Display the image along with the computed class probabilities.\n",
    "\n",
    "# What do the factors represent? Directions in which covariance is greatest among pixels.\n",
    "# *Extracting the factors and plotting them as images would be interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pytest\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import and label the training data\n",
    "face_ids        = [fp[-6:] for fp in glob.iglob('.\\\\data\\\\face-identification\\\\select-faces\\\\*')]\n",
    "face_fps        = glob.glob('.\\\\data\\\\face-identification\\\\select-faces\\\\*\\\\*.jpg')\n",
    "training_data   = np.array([np.ravel(imresize(imread(fp, flatten=True)/255, size = [25, 25])) for fp in face_fps])\n",
    "training_labels = [face_ids.index(name) for name in [fp.split('\\\\')[-2] for fp in face_fps]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test functions for fit_likelihood()\n",
    "def test_likelihood_inputs(training_data, training_labels, n_factors):\n",
    "    assert n_factors > 0\n",
    "    assert type(training_labels)    == list\n",
    "    assert type(training_data)      == np.ndarray\n",
    "    assert type(training_labels[0]) == int\n",
    "    assert len(training_labels)     == training_data.shape[0]\n",
    "\n",
    "def test_likelihood_outputs(klikelihood_params, datum_length, n_factors):\n",
    "    assert test_likelihood_mean_dim(klikelihood_params[1], datum_length)\n",
    "    assert test_likelihood_factor_dim(klikelihood_params[2], datum_length, n_factors)\n",
    "    assert test_likelihood_covar_dim(klikelihood_params[3], datum_length)\n",
    "    assert test_likelihood_covar_psd(klikelihood_params[3])\n",
    "    assert test_likelihood_covar_sym(klikelihood_params[3])\n",
    "\n",
    "def test_likelihood_mean_dim(mean_vector, datum_length):\n",
    "    assert len(mean_vector) == datum_length\n",
    "\n",
    "def test_likelihood_factor_dim(factor_matrix, datum_length, n_factors):\n",
    "    assert factor_matrix.shape == (datum_length, n_factors)\n",
    "\n",
    "def test_likelihood_covar_positive(covar_matrix):\n",
    "    assert np.all(covar_matrix >= 0)\n",
    "    \n",
    "def test_likelihood_covar_dim(covar_matrix, datum_length):\n",
    "    assert covar_matrix.shape == (datum_length, datum_length)\n",
    "    \n",
    "def test_likelihood_covar_sym(covar_matrix):\n",
    "    assert np.all(covar_matrix == covar_matrix.T)\n",
    "\n",
    "def test_likelihood_covar_psd(covar_matrix):\n",
    "    assert np.all(np.linalg.eigvals(covar_matrix) >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_prior(training_labels):\n",
    "    # Receives a list of training labels indicating face ID\n",
    "    # Returns a numpy array of ID prior probabilities\n",
    "    priors = [sum(training_labels == ID)/len(training_labels) for ID in np.unique(training_labels)]\n",
    "    return np.array(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_likelihood(training_data, training_labels, n_factors):\n",
    "    # training_data   -> numpy array with rows of grayscale image vectors\n",
    "    # training_labels -> list of associated integer face IDs\n",
    "    # n_factors       -> Number of factors to use in factor analyzer\n",
    "    # Iterates over world states and fits the parameters of their associated likelihood distributions\n",
    "    test_likelihood_inputs(training_data, training_labels, n_factors)\n",
    "    class_IDs         = np.unique(training_labels)\n",
    "    likelihood_params = [None]*len(class_IDs) # List containing a set of parameters for each world state\n",
    "    datum_length      = training_data.shape[1]\n",
    "    for k in np.unique(class_IDs):\n",
    "        k_data               = training_data[training_labels == k, :] # Images containing kth person\n",
    "        klikelihood_params   = EM(k_data, n_factors, datum_length) # Fit the kth FA's parameters -> [mu_k, phi_k, covar_k]\n",
    "        #assert test_likelihood_outputs(klikelihood_params, datum_length, n_factors)\n",
    "        likelihood_params[k] = klikelihood_params\n",
    "    return likelihood_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def EM(training_data, n_factors, datum_length):\n",
    "    # Returns parameters that fit a factor analyzer to the given data\n",
    "    # training_data -> np array with rows of vectorized input images\n",
    "    # n_factors     -> Number of factors to model the data's covariance with\n",
    "    # 1. Randomly initialize parameters\n",
    "    training_data = np.mat(training_data)\n",
    "    mu_upd      = np.mat(np.random.uniform([1]*datum_length)).T # Vector\n",
    "    phi_upd     = np.mat([np.random.normal(size = n_factors) for _ in range(datum_length)]) # Matrix\n",
    "    covar_upd   = np.mat(np.random.normal(0, 100)*np.identity(datum_length))\n",
    "    n_datum = training_data.shape[0]\n",
    "    # 2. Iterate over E and M steps until boundary ceases to shift\n",
    "    error = 1e5\n",
    "    while (error > 1) :\n",
    "        [mu, phi, covar]             = [mu_upd, phi_upd, covar_upd]\n",
    "        expectations                 = E_step(training_data, mu, phi, covar, n_datum) # [N x 2] np.array: [(E[h_i], E[h_i h_i.T]), ...]\n",
    "        [mu_upd, phi_upd, covar_upd] = M_step(training_data, expectations, n_datum) #\n",
    "        mu_error                    = np.max(abs(mu_upd - mu))\n",
    "        phi_error                   = np.max(abs(phi_upd - phi))\n",
    "        covar_error                 = np.max(abs(covar_upd - covar))\n",
    "        error = max([phi_error, mu_error, covar_error])\n",
    "        print(error)\n",
    "    return [mu_upd, phi_upd, covar_upd]\n",
    "# The hidden variable is a vector describing the shift in the normal's mean through the subspace - this shift is conditional\n",
    "# on each image, meaning that well-represented images will produce many shifts to a particular part of the subspace. This\n",
    "# further means that the factors will tend to be aligned in the direction of shift (see the computation of the factors in\n",
    "# the M-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def E_step(training_data, mu, phi, covar, n_datum):\n",
    "    I  = np.identity(phi.shape[1])\n",
    "    expectations = [None]*n_datum\n",
    "    for i in range(n_datum):\n",
    "        x                = np.mat(training_data[i, :]).T\n",
    "        inv_term         = np.linalg.inv(phi.T * np.linalg.inv(covar) * phi + I)\n",
    "        E_h              = inv_term * phi.T  * np.linalg.inv(covar) * (x - mu)\n",
    "        E_hh             = inv_term + E_h * E_h.T\n",
    "        expectations[i]  = [E_h, E_hh]\n",
    "    return expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def M_step(training_data, expectations, n_datum):\n",
    "    x         = training_data\n",
    "    # Mu\n",
    "    mu_hat    = np.sum(training_data, axis = 0).T/n_datum\n",
    "    # Phi\n",
    "    list_E_h  = np.array([expec[0] for expec in expectations])\n",
    "    list_E_hh = np.array([expec[1] for expec in expectations])\n",
    "    phi_t1    = np.sum(np.array([(x[i, :].T - mu_hat) * list_E_h[i].T for i in range(n_datum)]), axis = 0)\n",
    "    phi_t2    = np.linalg.inv(np.sum(list_E_hh, axis = 0))\n",
    "    phi_hat   = np.mat(phi_t1) * np.mat(phi_t2)\n",
    "    # Sigma\n",
    "    sum_of_sq = 0\n",
    "    for i in range(n_datum):\n",
    "        sum_of_sq += np.diag(((x[i, :].T - mu_hat) * (x[i, :].T - mu_hat).T)\n",
    "                             - (phi_hat * list_E_h[i] * (x[i, :].T - mu_hat).T))/n_datum\n",
    "    covar_hat  = np.identity(len(mu_hat))\n",
    "    np.fill_diagonal(covar_hat, sum_of_sq)\n",
    "    return [mu_hat, phi_hat, covar_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053.02000083\n",
      "672.895139898\n",
      "127.261924077\n",
      "16.3865056276\n",
      "13.9671806469\n",
      "12.5880699107\n",
      "11.4247960671\n",
      "10.37264174\n",
      "9.40143466423\n",
      "8.21691184501\n",
      "6.65223748207\n",
      "4.88829405333\n",
      "3.39003389564\n",
      "2.2979969495\n",
      "1.58216619074\n",
      "1.12069600724\n",
      "0.811635885222\n",
      "829.813510784\n",
      "790.417562198\n",
      "11.5500498146\n",
      "2.77036248134\n",
      "1.834938904\n",
      "1.34361623325\n",
      "0.979091627937\n",
      "1183.49803016\n",
      "948.130070673\n",
      "54.2062456053\n",
      "6.46788500038\n",
      "5.19881779761\n",
      "4.84847062795\n",
      "4.01864019626\n",
      "2.56505847332\n",
      "1.46569747715\n",
      "0.81564296874\n"
     ]
    }
   ],
   "source": [
    "n_factors = 1\n",
    "fit_parameters = fit_likelihood(training_data, training_labels, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xaff9828>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niYL6F8cvxRAyd78lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaf71898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(fit_parameters[0][0], [25, 25]), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
